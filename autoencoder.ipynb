{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "Dense, Flatten, Reshape, Conv2DTranspose, Activation\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder:\n",
    "    '''\n",
    "    Autoencoder represents a Deep Convolutional autoencoder architecture with mirrored\n",
    "    encoder and decoder components.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_shape, conv_filters, conv_kernels, conv_strides, latent_space_dim):\n",
    "        self.input_shape  = input_shape  #ex) [width, height, channel]\n",
    "        self.conv_filters = conv_filters #ex) [2,4,8]: number of conv_filter for each convolutional layer\n",
    "        self.conv_kernels = conv_kernels #ex) [3,5,4]: filter size of each conv layer\n",
    "        self.conv_strides = conv_strides #ex) [1,2,2]: stride size \n",
    "        self.latent_space_dim = latent_space_dim #int: number of dim \n",
    "        \n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model   = None\n",
    "        \n",
    "        #private attributes\n",
    "        self._num_conv_layers = len(conv_filters) \n",
    "        self._shape_before_bottleneck = None\n",
    "        \n",
    "        #construct model \n",
    "        self._build()\n",
    "        \n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        \n",
    "    def _build(self):\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "#         self._build_autoencoder()\n",
    "        \n",
    "    def _build_decoder(self):\n",
    "        decoder_input = self._add_decoder_input()\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input, decoder_output, name = \"decoder\")\n",
    "        \n",
    "    def _add_decoder_input(self):\n",
    "        return Input(shape = self.latent_space_dim, name = \"decoder_input\")\n",
    "    \n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        #we want to have same number of neurons before the bottleneck process\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck) # [width, height, channel] -> need their product\n",
    "        dense_layer = Dense(num_neurons, name = \"decoder_dense\")(decoder_input)\n",
    "        \n",
    "        return dense_layer\n",
    "        \n",
    "    def _add_reshape_layer(self, dense_layer):\n",
    "        #reshaping to 3D block\n",
    "        return Reshape(target_shape = self._shape_before_bottleneck)(dense_layer)\n",
    "    \n",
    "    def _add_conv_transpose_layers(self, x):\n",
    "        '''\n",
    "        Add conv transpose blocks\n",
    "        Loop thru all the encoder's conv layer in reverse order and stop at the first layer\n",
    "        '''\n",
    "        \n",
    "        for layer_index in reversed(range(1,self._num_conv_layers)):\n",
    "            x = self._add_conv_transpose_layer(layer_index, x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def _add_conv_transpose_layer(self, layer_index, x):\n",
    "        \n",
    "        layer_num = self._num_conv_layers - layer_index\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters = self.conv_filters[layer_index],\n",
    "            kernel_size = self.conv_kernels[layer_index], \n",
    "            strides = self.conv_strides[layer_index],\n",
    "            padding = \"same\", \n",
    "            name = \"decoder_conv_transpose_layer_{}\".format(layer_num)\n",
    "        )\n",
    "        \n",
    "        x = conv_transpose_layer(x)\n",
    "        x = ReLU(name = \"decoder_relu_{}\".format(layer_num))(x)\n",
    "        x = BatchNormalization(name = \"decoder_bn_{}\".format(layer_num))(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def _add_decoder_output(self, x):\n",
    "        \n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters = 1,\n",
    "            kernel_size = self.conv_kernels[0], \n",
    "            strides = self.conv_strides[0],\n",
    "            padding = \"same\", \n",
    "            name = \"decoder_conv_transpose_layer_{}\".format(self._num_conv_layers)\n",
    "        )    \n",
    "        \n",
    "        x = conv_transpose_layer(x)\n",
    "        output_layer = Activation(activation = \"sigmoid\", name = \"sigmoid_layer\")(x)\n",
    "        \n",
    "        return output_layer\n",
    "    \n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottlenext(conv_layers)\n",
    "        self.encoder = Model(encoder_input, bottleneck, name = \"encoder\") #input/output of the encoder \n",
    "        \n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape = self.input_shape, name = \"encoder_input\")\n",
    "    \n",
    "    def _add_conv_layers(self,encoder_input):\n",
    "        '''\n",
    "        Creates all convolutional layers needed for encoder\n",
    "        '''\n",
    "        x = encoder_input\n",
    "        \n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x) #iteratively adding layer to nn graph\n",
    "            \n",
    "        return x\n",
    "        \n",
    "    def _add_conv_layer(self, layer_index, x):\n",
    "        '''\n",
    "        Add convolutional block to a graph of layers consisting of conv2_d + Relu + batch normalization\n",
    "        '''\n",
    "        layer_num = layer_index + 1\n",
    "        \n",
    "        conv_layer = Conv2D(\n",
    "            filters = self.conv_filters[layer_index], \n",
    "            kernel_size = self.conv_kernels[layer_index], \n",
    "            strides = self.conv_strides[layer_index], \n",
    "            padding = \"same\", \n",
    "            name = \"encoder_conv_layer_{}\".format(layer_num)\n",
    "        )\n",
    "        \n",
    "        x = conv_layer(x) #using Functional api\n",
    "        x = ReLU(name = \"encoder_relue_{}\".format(layer_num))(x)\n",
    "        x = BatchNormalization(name = \"encoder_bn_{}\".format(layer_num))(x)\n",
    "        \n",
    "        return x \n",
    "\n",
    "    def _add_bottlenext(self, x):\n",
    "        '''\n",
    "        Flatten input and attach Dense layer as bottleneck\n",
    "        return encoder output, shape of the output before flatten for decoder\n",
    "        '''\n",
    "    \n",
    "        # Returns the shape of tensor or variable as a list of int or NULL entries.\n",
    "        # shape of data (4-dim array): [batch_size, width, height, channel] \n",
    "        self._shape_before_bottleneck = K.int_shape(x)[1:] \n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(units = self.latent_space_dim, name = \"encoder_output\")(x)\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_layer_1 (Conv2D (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "encoder_relue_1 (ReLU)       (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_bn_1 (BatchNormaliza (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "encoder_conv_layer_2 (Conv2D (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "encoder_relue_2 (ReLU)       (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "encoder_bn_2 (BatchNormaliza (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "encoder_conv_layer_3 (Conv2D (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "encoder_relue_3 (ReLU)       (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "encoder_bn_3 (BatchNormaliza (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "encoder_conv_layer_4 (Conv2D (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "encoder_relue_4 (ReLU)       (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "encoder_bn_4 (BatchNormaliza (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 2)                 6274      \n",
      "=================================================================\n",
      "Total params: 99,842\n",
      "Trainable params: 99,394\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "decoder_dense (Dense)        (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "decoder_relu_3 (ReLU)        (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_3 (BatchNormaliza (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "sigmoid_layer (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 121,537\n",
      "Trainable params: 121,153\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #initiating autoencoder\n",
    "    autoencoder = Autoencoder(input_shape = (28,28,1),\n",
    "                              conv_filters=(32,64,64,64), \n",
    "                              conv_kernels = (3, 3, 3, 3), \n",
    "                              conv_strides=(1, 2, 2, 1), \n",
    "                              latent_space_dim= 2\n",
    "                             )\n",
    "    \n",
    "    autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7* 7* 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
